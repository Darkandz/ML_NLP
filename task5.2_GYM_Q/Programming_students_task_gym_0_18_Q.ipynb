{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9QLe_T6GZUd"
      },
      "source": [
        "# Задание на программирование"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYlIf2yHv8hz"
      },
      "source": [
        "**Выполнять задание следует с текущими значениями гиперпараметров. Для проверки ниже будут приведены ответы, которые должны получиться в результате выполнения задания. После того, как все ответы совпадут, можно будет использовать полученный блокнот для выполнения индивидуального задания.**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDQzNIZXAoFE"
      },
      "source": [
        "Зададим гиперпараметры модели"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NOMw2ZbOAmOZ"
      },
      "source": [
        "epsilon = 0.1 # Параметр эпсилон при использовании эпсилон жадной стратегии\n",
        "gamma = 0.8 # Коэффциент дисконтирования гамма\n",
        "random_seed = 9 #Random seed\n",
        "time_delay = 1 # Задержка времени при отрисовке процесса игры после обучения (секунды)\n",
        "lr_rate = 0.9 #Коэффициент скорости обучения альфа"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQu5IYHX8jId"
      },
      "source": [
        "Импортируем библиотеки, создаем свою среду размера 6х6. S обозначает точку старта. F -- лед безопасен, H -- проталина, G -- цель. Параметр `is_slippery=False` отвечает за условное отсутствие скольжения. То есть если агент выбрал действие пойти направо, то он переместится в соответствующее состояние. В общем случае из-за \"скольжения\" можно оказаться в другом состоянии. Мы также скопировали из библиотки GYM и слегка модифицировали функцию ```generate_random_map ```, для того, чтобы генерировать произвольные карты на основе ```random_seed ```.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "awL7CCCwD6C3",
        "outputId": "26bf365d-18ea-4d55-cbeb-f8d4376b65c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install -q --upgrade gym==0.18.0\n",
        "import gym\n",
        "import numpy as np\n",
        "import time\n",
        "from IPython.display import clear_output\n",
        "\n",
        "\n",
        "def generate_random_map(size, p, sd):\n",
        "    \"\"\"Generates a random valid map (one that has a path from start to goal)\n",
        "    :param size: size of each side of the grid\n",
        "    :param p: probability that a tile is frozen\n",
        "    \"\"\"\n",
        "    valid = False\n",
        "    np.random.seed(sd)\n",
        "\n",
        "    # DFS to check that it's a valid path.\n",
        "    def is_valid(res):\n",
        "        frontier, discovered = [], set()\n",
        "        frontier.append((0,0))\n",
        "        while frontier:\n",
        "            r, c = frontier.pop()\n",
        "            if not (r,c) in discovered:\n",
        "                discovered.add((r,c))\n",
        "                directions = [(1, 0), (0, 1), (-1, 0), (0, -1)]\n",
        "                for x, y in directions:\n",
        "                    r_new = r + x\n",
        "                    c_new = c + y\n",
        "                    if r_new < 0 or r_new >= size or c_new < 0 or c_new >= size:\n",
        "                        continue\n",
        "                    if res[r_new][c_new] == 'G':\n",
        "                        return True\n",
        "                    if (res[r_new][c_new] not in '#H'):\n",
        "                        frontier.append((r_new, c_new))\n",
        "        return False\n",
        "\n",
        "    while not valid:\n",
        "        p = min(1, p)\n",
        "        res = np.random.choice(['F', 'H'], (size, size), p=[p, 1-p])\n",
        "        res[0][0] = 'S'\n",
        "        res[-1][-1] = 'G'\n",
        "        valid = is_valid(res)\n",
        "    return [\"\".join(x) for x in res]\n",
        "\n",
        "#Генерация карты\n",
        "random_map = generate_random_map(size=6, p=0.8, sd = random_seed) #Создаем свою карту\n",
        "env = gym.make(\"FrozenLake-v0\", desc=random_map, is_slippery=False) #Инициализируем среду\n",
        "print(\"Ваша карта\")\n",
        "env.render() #Выводим карту на экран"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ваша карта\n",
            "\n",
            "\u001b[41mS\u001b[0mFFFFF\n",
            "FFFFFH\n",
            "HFFFHF\n",
            "FFFFHF\n",
            "HHHFFH\n",
            "FHHFFG\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MDCexoEU9a_c"
      },
      "source": [
        "Функции выбора действия и обновления таблицы ценности действий. Строчка *** используется для того, чтобы проверять ответы в openedx. Вне рамках академической задачи лучше использовать оригинальный метод класса `environment`, то есть:\n",
        "\n",
        "`action = env.action_space.sample()`"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5TbDqn6G_Pt"
      },
      "source": [
        "# Задача 1\n",
        "Дополните функцию ```learn()```, чтобы в результате ее вызова обновлялось значение ценности текущего действия согласно алгоритму Q-обучения\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CdQBpxaTOK7u"
      },
      "source": [
        "def choose_action(state):\n",
        "    action=0\n",
        "    if np.random.uniform(0, 1) < epsilon:\n",
        "        action = np.random.randint(0,env.action_space.n) #***\n",
        "    else:\n",
        "        action = np.random.choice(np.array(np.argwhere(Q[state, :] == np.amax(Q[state, :])).flatten().tolist()))\n",
        "    return action\n",
        "\n",
        "def learn(state, state2, reward, action, done):\n",
        "  if done:\n",
        "    Q[state, action] = Q[state, action] + lr_rate*(reward - Q[state, action]) #Ваш код здесь\n",
        "  else:\n",
        "    Q[state, action] = Q[state, action] + lr_rate*(reward + gamma*(np.amax(Q[state2, :])) - Q[state, action])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7COGeyA_Ist3"
      },
      "source": [
        "# Задача 2\n",
        "Дополните следующий код так, чтобы в результате обучения модели можно было узнать количество побед и номер игры (`game`), на котором агент впервые одержал пятую победу подряд."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0adDl7NvJoQP"
      },
      "source": [
        "Поясним, что возвращает функция ```env.step(action)```\n",
        "\n",
        "```state2``` -- следующее состояние\n",
        "\n",
        "```reward``` -- награда\n",
        "\n",
        "```done``` -- флаг окончания игры. True в случае победы или падения в проталину. False в остальных случаях.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aq92-dWiOchF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da42ae9a-b267-493b-cfab-fef2e714fed5"
      },
      "source": [
        "from tqdm import tqdm\n",
        "# Inititalization\n",
        "np.random.seed(random_seed)\n",
        "total_games = 10000\n",
        "max_steps = 100\n",
        "Q = np.zeros((env.observation_space.n, env.action_space.n))\n",
        "#Main cycle\n",
        "wins = 0\n",
        "first5c = 0\n",
        "first5g = -1\n",
        "pg = 0\n",
        "for game in tqdm(range(total_games)):\n",
        "    state = env.reset()\n",
        "    t = 0\n",
        "    while t < max_steps:\n",
        "        \n",
        "        t += 1\n",
        "\n",
        "        action = choose_action(state)\n",
        "\n",
        "        state2, reward, done, info = env.step(action)\n",
        "\n",
        "        if t == max_steps:\n",
        "          done = True  \n",
        "\n",
        "        learn(state, state2, reward, action, done)\n",
        "\n",
        "        state = state2\n",
        "\n",
        "        if done:\n",
        "          if reward == 1:\n",
        "            wins +=1\n",
        "            if first5g == -1:\n",
        "              first5c += 1\n",
        "              if first5c == 5:\n",
        "                first5g = game+1\n",
        "          else:\n",
        "            first5c = 0\n",
        "          break\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10000/10000 [00:21<00:00, 472.25it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JFuxsqdRLOS9"
      },
      "source": [
        "Вывод ответов при заданных параметрах"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZbJtFnhLa7w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "990ee7fb-1a1f-4e1e-d800-0a26d51a66b2"
      },
      "source": [
        "print(\"Количество побед в серии из 10 000 игр: \", wins )\n",
        "print(\"Пять побед подряд впервые было одержано в игре \", first5g )\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Количество побед в серии из 10 000 игр:  8267\n",
            "Пять побед подряд впервые было одержано в игре  367\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSXdSiG2WI71"
      },
      "source": [
        "Должны получиться следующие результаты.\n",
        "\n",
        "\n",
        "*  Количество побед в серии из 10 000 игр:  7914\n",
        "*  Пять побед подряд впервые было одержано в игре  885\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nazZaAbwQGBt"
      },
      "source": [
        "Произведем одну игру, чтобы проследить за действиями агента. При этом будем считать модель полностью обученной, то есть действия выбираются жадно, значения ценностей действий в таблице не обновляются."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5ysllZjEQXLa",
        "outputId": "39ef21ea-e444-492f-8274-2889e022c330",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import time\n",
        "#Жадный выбор действий\n",
        "def choose_action_one_game(state):\n",
        "    action = np.random.choice(np.array(np.argwhere(Q[state, :] == np.amax(Q[state, :])).flatten().tolist()))\n",
        "    return action\n",
        "\n",
        "states=[]#Массив для сохранения состояний агента в течение игры\n",
        "t = 0\n",
        "state = env.reset()\n",
        "wn = 0\n",
        "while(t<100):\n",
        "  env.render()\n",
        "  time.sleep(time_delay)\n",
        "  clear_output(wait=True)\n",
        "  action = choose_action_one_game(state)  \n",
        "  state2, reward, done, info = env.step(action)  \n",
        "  states.append(state)\n",
        "  state = state2\n",
        "  t += 1\n",
        "  if done and reward == 1:\n",
        "    wn=1\n",
        "  if done:\n",
        "    break\n",
        "if wn == 1:\n",
        "  print(\"!!!Победа!!!\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "!!!Победа!!!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x696NulpReFI"
      },
      "source": [
        "Отобразим маршрут"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UKMCMdpOTcXy",
        "outputId": "c8e75c7e-9512-4354-fd35-a8fd51f3694c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def make_maze_pic(maze):\n",
        "  maze_pic=[]\n",
        "  for i in range(len(maze)):\n",
        "    row = []\n",
        "    for j in range(len(maze[i])):\n",
        "      if maze[i][j] == 'S':\n",
        "        row.append(0)\n",
        "      if maze[i][j] == 'F':\n",
        "        row.append(0)\n",
        "      if maze[i][j] == 'H':\n",
        "        row.append(1)\n",
        "      if maze[i][j] == 'G':\n",
        "        row.append(0)\n",
        "    maze_pic.append(row)\n",
        "  maze_pic = np.array(maze_pic)\n",
        "  return maze_pic\n",
        "  \n",
        "\n",
        "#Make maze fit to plot\n",
        "maze_pic = make_maze_pic(random_map)\n",
        "nrows, ncols = maze_pic.shape\n",
        "\n",
        "#Arrays of picture elements\n",
        "rw = np.remainder(states,nrows)\n",
        "cl = np.floor_divide(states,nrows)\n",
        "if wn == 1:\n",
        "  rw = np.append(rw, [nrows-1])\n",
        "  cl = np.append(cl,[ncols-1])\n",
        "\n",
        "#Picture plotting\n",
        "fig, ax1 = plt.subplots(1, 1, tight_layout=True)\n",
        "ax1.clear()\n",
        "ax1.set_xticks(np.arange(0.5, nrows, step=1))\n",
        "ax1.set_xticklabels([])\n",
        "ax1.set_yticks(np.arange(0.5, ncols, step=1))\n",
        "ax1.set_yticklabels([])\n",
        "ax1.grid(True)\n",
        "ax1.plot([0],[0], \"gs\", markersize=40)  # start is a big green square\n",
        "ax1.text(0, 0.2,\"Start\", ha=\"center\", va=\"center\", color=\"white\", fontsize=12) #Start text\n",
        "ax1.plot([nrows-1],[ncols-1], \"rs\", markersize=40)  # exit is a big red square\n",
        "ax1.text(nrows-1, ncols-1+0.2,\"Finish\", ha=\"center\", va=\"center\", color=\"white\", fontsize=12) #Exit text\n",
        "ax1.plot(rw,cl, ls = '-', color = 'blue') #Blue lines path\n",
        "ax1.plot(rw,cl, \"bo\")  # Blue dots visited cells\n",
        "ax1.imshow(maze_pic, cmap=\"binary\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f6f996ca940>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}