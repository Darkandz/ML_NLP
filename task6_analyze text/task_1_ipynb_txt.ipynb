{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LUuyLVDZ4s8r"
      },
      "source": [
        "## ЗАДАНИЕ ДЛЯ ПРОГРАММИРУЮЩИХ"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzW2MUlrG7Sf"
      },
      "source": [
        "Изменяем значения по заданию"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64uxt-07IEec"
      },
      "source": [
        "DATA_URL = \"http://az.lib.ru/t/turgenew_i_s/text_0070.shtml\" # Ссылка на файл из Задания\n",
        "more_words_count = 100\n",
        "tokens_more_count = 20"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwrBkeLnHuA1"
      },
      "source": [
        "Устанавливаем библиотеки"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5Fr5swwYfz5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc384f6f-87a0-4027-a4fc-0bf0e2153567"
      },
      "source": [
        "! pip install -q PyYaml==5.3.1\n",
        "! pip install -q rnnmorph==0.4.0\n",
        "! pip install -q nltk==3.2.5\n",
        "! pip install 'h5py==2.10.0' -force-reinstall"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |█▏                              | 10 kB 24.5 MB/s eta 0:00:01\r\u001b[K     |██▍                             | 20 kB 30.8 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 30 kB 38.3 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 40 kB 24.2 MB/s eta 0:00:01\r\u001b[K     |██████                          | 51 kB 18.6 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 61 kB 16.6 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 71 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 81 kB 14.8 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 92 kB 16.3 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 102 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 112 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 122 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 133 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 143 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 153 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 163 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 174 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 184 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 194 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 204 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▌      | 215 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 225 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 235 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 245 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 256 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 266 kB 14.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 269 kB 14.4 MB/s \n",
            "\u001b[?25h  Building wheel for PyYaml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 10.5 MB 12.8 MB/s \n",
            "\u001b[K     |████████████████████████████████| 55 kB 2.4 MB/s \n",
            "\u001b[K     |████████████████████████████████| 8.2 MB 60.8 MB/s \n",
            "\u001b[?25h  Building wheel for rnnmorph (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for russian-tagsets (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Looking in links: orce-reinstall\n",
            "\u001b[33mWARNING: Location 'orce-reinstall' is ignored: it is either a non-existing path or lacks a specific scheme.\u001b[0m\n",
            "Collecting h5py==2.10.0\n",
            "  Downloading h5py-2.10.0-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 13.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.7/dist-packages (from h5py==2.10.0) (1.19.5)\n",
            "Installing collected packages: h5py\n",
            "  Attempting uninstall: h5py\n",
            "    Found existing installation: h5py 3.1.0\n",
            "    Uninstalling h5py-3.1.0:\n",
            "      Successfully uninstalled h5py-3.1.0\n",
            "Successfully installed h5py-2.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gbxMKqhPH1Dk"
      },
      "source": [
        "Запускаем код и смотрим внизу ответы"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "24zMUhvi99AV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e717ce75-a1a4-46a5-cca3-ffa0f57dd46a"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "import nltk\n",
        "import warnings\n",
        "import urllib.request\n",
        "from tqdm import tqdm\n",
        "from nltk import FreqDist\n",
        "from bs4 import BeautifulSoup\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import sent_tokenize, word_tokenize\n",
        "warnings.filterwarnings('ignore')\n",
        "nltk.download('punkt', quiet=True)\n",
        "nltk.download(\"stopwords\", quiet=True)\n",
        "\n",
        "from rnnmorph.predictor import RNNMorphPredictor\n",
        "predictor = RNNMorphPredictor(language=\"ru\")\n",
        "opener = urllib.request.URLopener({})\n",
        "resource = opener.open(DATA_URL)\n",
        "raw_text = resource.read().decode(resource.headers.get_content_charset())\n",
        "\n",
        "soup = BeautifulSoup(raw_text, features=\"html.parser\")\n",
        "\n",
        "for script in soup([\"script\", \"style\"]):\n",
        "    script.extract()\n",
        "\n",
        "cleaned_text = soup.get_text()\n",
        "tokenized_sentences = [word_tokenize(sentence) for sentence in sent_tokenize(cleaned_text)]\n",
        "predictions = [[pred.normal_form for pred in sent if pred.normal_form.isalpha()] for sent in tqdm(predictor.predict_sentences(sentences=tokenized_sentences), \"sentences\") ] # ИСПРАВИЛ НА ТОЛЬКО БУКВЫ\n",
        "non_uniq_tokens = [word for sentence in predictions for word in sentence]\n",
        "\n",
        "answers = {}\n",
        "for i in non_uniq_tokens:\n",
        "  if i in answers:\n",
        "    answers[i] += 1\n",
        "  else:\n",
        "    answers[i] = 1\n",
        "\n",
        "STOPWORDS = set(stopwords.words(\"russian\"))\n",
        "\n",
        "t = 1\n",
        "counter = more_words_count + 1\n",
        "while counter > more_words_count:\n",
        "  counter = 0\n",
        "  n_answers = []\n",
        "  for i in answers:\n",
        "    if (answers[i] > t):\n",
        "      n_answers.append(i)\n",
        "      counter += 1\n",
        "  t += 1\n",
        "\n",
        "counter = 0\n",
        "for i in n_answers:\n",
        "  if i in stopwords.words(\"russian\"):\n",
        "    counter += 1\n",
        "\n",
        "counter1 = 0\n",
        "for i in answers:\n",
        "  if (answers[i] > tokens_more_count):\n",
        "    counter1 += 1\n",
        "print(\"\\n\")\n",
        "\n",
        "print(\"Введите количество предложений\")\n",
        "print(\"Ответ:\", len(predictions))\n",
        "\n",
        "print(\"Введите количество токенов, состоящих только из букв\")\n",
        "print(\"Ответ:\", len(non_uniq_tokens))\n",
        "\n",
        "print(f\"Какую долю среди {more_words_count} самых частотных токенов в произведении занимают слова, не входящие в стоп-лист?\")\n",
        "print(\"Ответ:\", (more_words_count - counter) / more_words_count)\n",
        "\n",
        "print(f\"Сколько токенов встречается в тексте строго больше {tokens_more_count} раз?\")\n",
        "print(\"Ответ:\", counter1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "sentences: 100%|██████████| 532/532 [00:00<00:00, 87786.99it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Введите количество предложений\n",
            "Ответ: 532\n",
            "Введите количество токенов, состоящих только из букв\n",
            "Ответ: 8354\n",
            "Какую долю среди 100 самых частотных токенов в произведении занимают слова, не входящие в стоп-лист?\n",
            "Ответ: 0.5\n",
            "Сколько токенов встречается в тексте строго больше 20 раз?\n",
            "Ответ: 52\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}